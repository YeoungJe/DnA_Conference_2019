{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tnrange\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_num(x) :\n",
    "    try : output = int(x)\n",
    "    except : output = \"remove\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing_text(x) :\n",
    "    tmp_text = str(x[0])\n",
    "    output = re.sub(\"<.*?>\",\"\",tmp_text)\n",
    "    output = re.sub(\"[\\n\\t▶◆▦■→&◇lt;ⓒ]\",\"\",output)\n",
    "    output = re.sub(\"\\\\[.*?\\\\]\",\"\",output)\n",
    "    output = re.sub(\"\\xa0\",\"\",output)\n",
    "    output = re.sub(\"@.*\",\"\",output)\n",
    "    output = re.sub(\"☞.*\",\"\",output)\n",
    "    output = re.sub(\"\\'\",\"\",output)\n",
    "    \n",
    "    output = re.sub(\"모바일로 읽는.*\",\"\",output)\n",
    "    output = re.sub(\"(머니마켓).*\",\"\",output)\n",
    "    output = re.sub(\"이데일리ON.*\",\"\",output)\n",
    "    output = re.sub(\"뉴스의 새 시대, 연합뉴스.*\",\"\",output)\n",
    "    output = re.sub(\"MBA도 모바일로 공부한다..*\",\"\",output)\n",
    "    output = re.sub(\"헤럴드 생생뉴스.*\",\"\",output)\n",
    "    output = re.sub(\"데일리안.*\",\"\",output)\n",
    "    output = re.sub(\"• .*\",\"\",output)\n",
    "    output = re.sub(\"한경닷컴.*\",\"\",output)\n",
    "    \n",
    "    output = re.sub(\"                     \\\\(\",\"\",output)\n",
    "    output = re.sub(\"    \",\"\",output)\n",
    "    output = re.sub(\"   \",\"\",output)\n",
    "    output = re.sub(\"  \",\"\",output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawling\n",
    "\n",
    "* 주요 뉴스 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### news_inform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://finance.naver.com\"\n",
    "csv_save_path = \"/home/ubunt/4-2/stock price/data/news_csv/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [str(x) for x in range(2010,2020)]\n",
    "months = [str(x) for x in range(1,13)]\n",
    "days = [str(x) for x in range(1,32)]\n",
    "select_days = []\n",
    "for y in years :\n",
    "    for m in months :\n",
    "        for d in days :\n",
    "            select_days.append(y + \"-\" + m + \"-\" + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba8f20a598f74907a6c343e8c41d211c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3528), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for day in tqdm_notebook(select_days[start_index:]) :\n",
    "    url = \"https://finance.naver.com/news/mainnews.nhn?date={}\".format(day)\n",
    "    res = requests.get(url)\n",
    "    if res.status_code == 200 : _\n",
    "    else : print(\"error :\", day)\n",
    "    soup = BeautifulSoup(res.text,\"html.parser\")\n",
    "    \n",
    "    # 페이지 수\n",
    "    tmp_pages = soup.select(\"table.Nnavi tr > td\")\n",
    "    pages = [find_num(x.find(\"a\").text) for x in tmp_pages]\n",
    "    try : pages.remove(\"remove\")\n",
    "    except : _\n",
    "        \n",
    "    for page_index in pages :\n",
    "        recent_url = url + \"&page={}\".format(page_index)\n",
    "        # 제목 & url\n",
    "        tmp_titles = soup.select('div.mainNewsList li.block1 dd.articleSubject a')\n",
    "        titles_append = soup.select('div.mainNewsList li.block1 dt.articleSubject a')\n",
    "        sub_titles = soup.select(\"dd.relArticle a\")\n",
    "\n",
    "        page_title = [x.text for x in tmp_titles]\n",
    "        page_url = [base_url + x.get(\"href\") for x in tmp_titles]\n",
    "        page_title.extend([x.text for x in titles_append])\n",
    "        page_url.extend([base_url + x.get(\"href\") for x in titles_append])\n",
    "        page_title.extend([x.text for x in sub_titles])\n",
    "        page_url.extend([base_url + x.get(\"href\") for x in sub_titles])\n",
    "\n",
    "        # 신문사 & 발행 일자\n",
    "        tmp_corp = soup.select('span.press')\n",
    "        tmp_date = soup.select('span.wdate')\n",
    "\n",
    "        page_corp = [x.text for x in tmp_corp]\n",
    "        page_date = [x.text for x in tmp_date]\n",
    "        \n",
    "        page_df = pd.DataFrame({\"date\" : page_date, \"title\" : page_title, \"corp\" : page_corp, \"url\" : page_url})\n",
    "    \n",
    "    if start_index == 0 :\n",
    "        news_inform = page_df\n",
    "    else :\n",
    "        news_inform = news_inform.append(page_df)\n",
    "    \n",
    "    start_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_inform.index = [x for x in range(news_inform.shape[0])]\n",
    "news_inform.to_csv(csv_save_path + \"news_inform_2019092721.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### news text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_inform = pd.read_csv(csv_save_path + \"news_inform_2019092721.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7297a527fc8c47b3bf046634b6d576eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33460), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for news_url in tqdm_notebook(news_inform.url[start_idx:]) :\n",
    "    res = requests.get(news_url)\n",
    "    assert res.status_code == 200\n",
    "    \n",
    "    soup = BeautifulSoup(res.text,\"html.parser\")\n",
    "    news_text = cleansing_text(soup.select(\"div.articleCont\"))\n",
    "    tmp_df = pd.DataFrame({\"text\" : [news_text], \"url\" : [news_url]})\n",
    "    \n",
    "    if start_idx == 0 :\n",
    "        news_text_df = tmp_df\n",
    "    else :\n",
    "        news_text_df = news_text_df.append(tmp_df)\n",
    "    \n",
    "    start_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
